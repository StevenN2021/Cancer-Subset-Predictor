{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c283197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "887fbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "counts = pd.read_csv('/Users/stevennguyen/Projects/Cancer-Subset-Predictor-/data/data.csv')\n",
    "labels = pd.read_csv('/Users/stevennguyen/Projects/Cancer-Subset-Predictor-/data/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e29b7a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 20531) (801,)\n"
     ]
    }
   ],
   "source": [
    "#Split into X and y\n",
    "X = counts.drop(columns=['Unnamed: 0'])\n",
    "y = labels['Class']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3c43002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: ['BRCA' 'COAD' 'KIRC' 'LUAD' 'PRAD']\n",
      "Encoding [4 3 4 4 0]\n",
      "Stored 'le' (LabelEncoder)\n"
     ]
    }
   ],
   "source": [
    "#encode labels because they are categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "labeling = le.classes_\n",
    "print(\"Class labels:\", labeling)\n",
    "print(\"Encoding\",y_encoded[:5])\n",
    "%store le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36dd7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y_encoded,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03741106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0000000000000009\n"
     ]
    }
   ],
   "source": [
    "#normalize data with minmax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "#print first 5 rows of normalized data\n",
    "print(X_train_norm.min(), X_train_norm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01f6a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19249878 0.         0.38787106 0.         0.07452687 0.\n",
      "  0.         0.13549514 0.         0.36033128 0.08081171 0.38438187\n",
      "  0.1037933  0.03694741 0.         0.         0.09226333 0.05603771\n",
      "  0.03736455 0.81332884 0.         0.23443093 0.         0.05422029\n",
      "  0.05774558 0.29927687 0.09537012 0.15122187 0.         0.\n",
      "  0.31392713 0.21379394 0.         0.07302434 0.81320645 0.29933376\n",
      "  0.         0.32436742 0.         0.7702225  0.42454696 0.40108438\n",
      "  0.86547619 0.68534116 0.93924342 0.         0.         0.41767057\n",
      "  0.         0.15792107 0.88473423 0.24542511 0.29370109 0.03813467\n",
      "  0.         0.17110692 0.81789369 0.         0.         0.\n",
      "  0.         0.15472955 0.         0.90834269 0.         0.3968782\n",
      "  0.07903288 0.32239238 0.02701807 0.16111581 0.41619222 0.16901832\n",
      "  0.18772585 0.58671123 0.19814954 0.         0.2423133  0.\n",
      "  0.61954444 0.69458063 0.63142824 0.13957117 0.37253118 0.1679237\n",
      "  0.0775279  0.         0.13468893 0.03454594 0.         0.\n",
      "  0.16410863 0.94221218 0.         0.         0.         0.\n",
      "  0.         0.13967713 0.82233002 0.         0.         0.\n",
      "  0.7112878  0.94002364 0.91537023 0.29116175 0.0368329  0.15043966\n",
      "  0.         0.41839323 0.         0.         0.         0.04413683\n",
      "  0.02419207 0.         0.75466701 0.         0.         0.\n",
      "  0.         0.         0.         0.58763277 0.         0.1129482\n",
      "  0.1733532  0.5328048  0.19626402 0.08287993 0.1946893  0.\n",
      "  0.74835447 0.03278108 0.         0.11725459 0.90723207 0.\n",
      "  0.         0.         0.20796575 0.65695533 0.28258577 0.38887946\n",
      "  0.65391645 0.88367564 0.         0.24877027 0.23964639 0.13835509]\n",
      " [0.3035628  0.         0.40743658 0.30973346 0.33647066 0.\n",
      "  0.         0.24042483 0.         0.57401089 0.90921689 0.43783219\n",
      "  0.49929011 0.10997283 0.06420773 0.56731517 0.02731871 0.\n",
      "  0.36224157 0.6994871  0.29999819 0.3007933  0.         0.\n",
      "  0.49161947 0.41933786 0.61445936 0.09457573 0.23795786 0.\n",
      "  0.21554313 0.06706247 0.11182544 0.20693464 0.82555123 0.21327322\n",
      "  0.07325789 0.18023071 0.24564112 0.26690182 0.         0.\n",
      "  0.74175195 0.63106655 0.80553312 0.         0.05158316 0.18172677\n",
      "  0.81152286 0.087313   0.86193379 0.55267052 0.29330048 0.16859326\n",
      "  0.         0.36476852 0.74575429 0.04325122 0.86032926 0.68677065\n",
      "  0.2261423  0.04574425 0.         0.50984041 0.12205315 0.53918436\n",
      "  0.11533735 0.         0.         0.         0.         0.\n",
      "  0.03949754 0.         0.1028981  0.06853255 0.6675328  0.\n",
      "  0.66762052 0.79058673 0.42651034 0.18100503 0.24025161 0.90247874\n",
      "  0.         0.89622893 0.23691988 0.13082543 0.         0.40192873\n",
      "  0.         0.82668291 0.         0.         0.         0.\n",
      "  0.08965044 0.         0.78401847 0.05067859 0.         0.\n",
      "  0.60458645 0.74829185 0.79910898 0.26824445 0.65076129 0.85070127\n",
      "  0.58386774 0.2245972  0.9120757  0.87881358 0.78903456 0.83225289\n",
      "  0.92026968 0.64913861 0.63496055 0.         0.         0.11310025\n",
      "  0.         0.         0.         0.         0.         0.19730323\n",
      "  0.13270473 0.26685659 0.         0.16647162 0.70585073 0.19547312\n",
      "  0.82819808 0.32083775 0.19335255 0.61636068 0.48780109 0.08064345\n",
      "  0.64198801 0.0355688  0.39118611 0.73004606 0.17699852 0.36543031\n",
      "  0.19283042 0.47636472 0.         0.06335274 0.24794241 0.53277887]\n",
      " [0.91427715 0.6674914  0.87129923 0.82981528 0.13750038 0.81662566\n",
      "  0.84492108 0.86173811 0.55418973 0.91431323 0.77921401 0.9606047\n",
      "  0.07765655 0.         0.87408419 0.88402779 0.09930566 0.\n",
      "  0.75825973 0.         0.         0.89651916 0.72094206 0.77754823\n",
      "  0.15380627 0.80972734 0.84642318 0.09887674 0.         0.\n",
      "  0.61289373 0.68028216 0.57294255 0.87089324 0.1703984  0.90478733\n",
      "  0.70015607 0.78469753 0.06140674 0.51886176 0.93191321 0.92710245\n",
      "  0.15613894 0.08959412 0.21238538 0.23068411 0.         0.58087879\n",
      "  0.17900129 0.78516696 0.25673794 0.88445916 0.38982796 0.89317703\n",
      "  0.94224046 0.15078768 0.18809816 0.16930266 0.66879007 0.95978526\n",
      "  0.74156765 0.24369668 0.23408195 0.13459301 0.32326548 0.77096068\n",
      "  0.83493292 0.         0.         0.         0.04766844 0.\n",
      "  0.         0.213828   0.70373841 0.05795066 0.79970996 0.6162509\n",
      "  0.13070684 0.1778195  0.28750559 0.0341885  0.49071878 0.50723314\n",
      "  0.94498952 0.         0.16950285 0.08912671 0.         0.80126153\n",
      "  0.32415151 0.10761086 0.05371612 0.15937484 0.         0.11892641\n",
      "  0.63714654 0.59633679 0.21284095 0.87226464 0.         0.66584933\n",
      "  0.12991401 0.16877558 0.23130407 0.39425245 0.         0.\n",
      "  0.35441894 0.85560165 0.         0.         0.02365756 0.08432378\n",
      "  0.02144417 0.         0.06649582 0.79610119 0.68201764 0.91775849\n",
      "  0.61811936 0.92496753 0.93019414 0.88141714 0.71057157 0.79002979\n",
      "  0.95558175 0.21657877 0.86771946 0.8055326  0.99515476 0.46061988\n",
      "  0.20918071 0.20840043 0.         0.53544108 0.10254886 0.83654356\n",
      "  0.60168964 0.         0.81814903 0.17727285 0.90652392 0.82692252\n",
      "  0.10811868 0.3575553  0.83410502 0.82070583 0.76397262 0.94081769]\n",
      " [0.67480985 0.         0.30273659 0.         0.17882191 0.07824594\n",
      "  0.03350127 0.23935875 0.13795283 0.         0.07700921 0.32034147\n",
      "  0.09961546 0.06140018 0.07752867 0.         0.29628911 0.\n",
      "  0.11683725 0.7673921  0.27372498 0.16951605 0.         0.\n",
      "  0.         0.32858207 0.03193731 0.18499149 0.         0.\n",
      "  0.24436994 0.18935797 0.10200572 0.06958827 0.80074455 0.31717026\n",
      "  0.03748415 0.26156033 0.2423609  0.77333189 0.44791426 0.43053168\n",
      "  0.81685908 0.83786545 0.82568509 0.05159324 0.04567797 0.39077802\n",
      "  0.         0.         0.8374643  0.25464284 0.84281956 0.24068534\n",
      "  0.06591852 0.13716034 0.81389948 0.14101363 0.03849883 0.03530555\n",
      "  0.         0.14914174 0.15094582 0.83042871 0.11133531 0.4137329\n",
      "  0.         0.33551543 0.49488945 0.59772229 0.43632862 0.40149234\n",
      "  0.0349759  0.86940432 0.13038646 0.03506631 0.29888736 0.04559732\n",
      "  0.7197066  0.52612565 0.71186715 0.19416848 0.06537858 0.17185162\n",
      "  0.09009227 0.         0.64544746 0.0772312  0.         0.\n",
      "  0.12050202 0.80258856 0.05740933 0.37311686 0.         0.0309034\n",
      "  0.         0.04856896 0.79254524 0.04487696 0.         0.\n",
      "  0.79533943 0.69141339 0.83541456 0.30118868 0.16931155 0.\n",
      "  0.13391875 0.33909076 0.         0.         0.         0.05658217\n",
      "  0.02291854 0.         0.74045082 0.         0.         0.\n",
      "  0.         0.08748577 0.03307009 0.03552147 0.0629809  0.03782381\n",
      "  0.0719888  0.19577516 0.         0.09631167 0.23685988 0.09311853\n",
      "  0.59838784 0.35378813 0.         0.         0.75365224 0.\n",
      "  0.         0.         0.31423976 0.56829941 0.         0.\n",
      "  0.08810893 0.72131304 0.03428653 0.0764963  0.20439445 0.        ]\n",
      " [0.         0.86033131 0.03031535 0.         0.27035348 0.\n",
      "  0.         0.10512992 0.         0.62621482 0.929655   0.57218163\n",
      "  0.93404355 0.09318007 0.06575833 0.         0.08667074 0.87398012\n",
      "  0.57104899 0.75166792 0.95077625 0.83865172 0.63780326 0.03417325\n",
      "  0.93587614 0.41557467 0.81495413 0.94318482 0.94441956 0.\n",
      "  0.27946612 0.12587133 0.04129343 0.83079712 0.75145431 0.25634462\n",
      "  0.38719974 0.18307976 0.04310977 0.22132832 0.07829519 0.\n",
      "  0.96655506 0.70729802 0.85951844 0.89709093 0.05299498 0.34762566\n",
      "  0.85757961 0.19467283 0.83054983 0.47095758 0.23821409 0.19140106\n",
      "  0.         0.83772171 0.79402877 0.8799032  0.96061595 0.72173599\n",
      "  0.85779533 0.72341793 0.86551328 0.716302   0.92411234 0.69079731\n",
      "  0.         0.14557701 0.         0.         0.03346498 0.\n",
      "  0.09310951 0.24897994 0.8270332  0.96397644 0.68662379 0.80364085\n",
      "  0.42217967 0.72462167 0.80476743 0.80610139 0.88854853 0.11928459\n",
      "  0.03647069 0.04094816 0.08011376 0.92064081 0.         0.32439565\n",
      "  0.32589308 0.70751947 0.         0.         0.         0.09907475\n",
      "  0.58487706 0.41210105 0.91663576 0.         0.         0.\n",
      "  0.74404738 0.56505176 0.84657065 0.24974043 0.19336126 0.\n",
      "  0.04707189 0.39830485 0.16266456 0.         0.         0.19167584\n",
      "  0.06101156 0.         0.34130313 0.04810047 0.         0.03645754\n",
      "  0.29302973 0.62162452 0.03836748 0.         0.0416548  0.89017206\n",
      "  0.58703063 0.3345924  0.14942339 0.06726323 0.31371783 0.04578068\n",
      "  0.84768953 0.08267274 0.         0.50153768 0.41997498 0.65456404\n",
      "  0.61937772 0.         0.49060846 0.74373494 0.58192836 0.91525572\n",
      "  0.         0.22600529 0.58969782 0.41108183 0.12331191 0.89575265]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevennguyen/anaconda3/envs/pyml/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:110: UserWarning: Features [    5    23  4370  4371  4808  4809  4814  4815  4816  4817  4819  4831\n",
      "  5288  7661  7662  7663  7664  7665  8121  9304  9306  9309  9314  9316\n",
      "  9320  9452  9744 10121 11958 12490 13991 14158 14159 14161 15138 15140\n",
      " 15141 15446 16566 16568 16569 16571 16574 16575 16576 16578 16579 16604\n",
      " 16634 16637 16677 16697 16698 16699 16700 16701 16702 16704 16705 16706\n",
      " 16707 16708 16709 16710 16711 16712 16713 16714 16715 16716 16717 16718\n",
      " 16719 16720 16721 16722 16723 16724 16725 16726 16727 16728 16729 16730\n",
      " 16731 16732 16733 16734 16735 16736 16737 16738 16739 16740 16741 16742\n",
      " 16743 16744 16745 16746 16748 16749 16750 16751 16752 16753 16754 16756\n",
      " 16757 16758 16759 16760 16761 16762 16763 16764 16765 16766 16767 16768\n",
      " 16769 16770 16771 16772 16774 16775 16776 16777 16778 16779 16780 16781\n",
      " 16782 16783 16785 16787 16788 16789 16790 16791 16792 16794 16795 16796\n",
      " 16798 16799 16800 16801 16802 16803 16804 16805 16806 16807 16808 16809\n",
      " 16810 16811 16812 16813 16816 16818 16819 16820 16821 16822 16823 16824\n",
      " 16826 16827 16830 16831 16832 16833 16834 16835 16836 16837 16838 16839\n",
      " 16840 16841 16842 16843 16844 16845 16846 16847 16848 16849 16850 16851\n",
      " 16852 16853 16854 16855 16856 16857 16858 16859 16860 16861 16862 16863\n",
      " 16864 16865 16866 16867 16868 16869 16870 16871 16872 16873 16874 16875\n",
      " 16876 16877 16878 16879 16880 16881 16882 16883 16884 16885 16886 16888\n",
      " 16889 16890 16891 16892 16893 16894 16895 16896 16897 16898 16899 16900\n",
      " 16901 16902 16903 16904 16905 16906 16907 16908 16909 16910 16911 16914\n",
      " 16915 16916 16917 16918 16920 16921 16922 16924 16925 16926 17899 18829\n",
      " 18902 18903 18908 18909 18910 18911 18914 18915 18992 19450 19451 19452\n",
      " 19671] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/stevennguyen/anaconda3/envs/pyml/lib/python3.13/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#feature selection with ANOVA F Score \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "selector = SelectKBest(score_func=f_classif, k=150) #select top 150 features\n",
    "X_train_selected = selector.fit_transform(X_train_norm, y_train)\n",
    "X_test_selected = selector.transform(X_test_norm)\n",
    "print(X_train_selected[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d279074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train_selected' (ndarray)\n",
      "Stored 'X_test_selected' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "#store variables \n",
    "%store X_train_selected\n",
    "%store X_test_selected\n",
    "%store y_train\n",
    "%store y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
